0 Introduction
This artifact includes source code, datasets and models of the paper "Efficient White-box Fairness Testing through Gradient Search" by Lingfeng Zhang, Yueling Zhang, Min Zhang in ISSTA'21.


1 Getting Started

1.1 Environment
Python3.6 + Tensorflow2.0 or later versions are recommended.
The following packages are also required: numpy, scikit-learn, pandas, joblib.


1.2 File Directory
├── ADF.py	# implementation of ADF
├── EIDIG.py	# implementation of EIDIG
├── datasets	# experiment datasets
├── experiments.py	# experimental functions
├── generation_utilities.py	# utilities
├── logging_data	# logging data
│   ├── generated_discriminatory_instances
│   ├── logging_data_from_tests
│   ├── seedwise_comparison
│   └── time_consumption
├── model_evaluation	# model evaluation in terms of classification performance and discrimination degree
│   ├── classification_evaluation.py
│   └── fairness_evaluation.py
├── models	# experiment models
│   ├── ensemble_models
│   ├── models_from_tests
│   ├── original_models
│   └── retrained_models
├── preprocessing	# dataset preprocessing
│   ├── pre_bank_marketing.py
│   ├── pre_census_income.py
│   └── pre_german_credit.py
├── readme.txt
├── reproducing.py	# experiments for the validation of our claims
├── test.py	# a simple test for the validation of general functionality
└── training	# model training
    ├── ensemble_training.py
    ├── retraining.py
    ├── train_bank_marketing.py
    ├── train_census_income.py
    └── train_german_credit.py


1.3 A Small Example
We provide a small example to validate the general functionality by generating some individual discriminatory instances with ADF, EIDIG-5, and EIDIG-INF, respectively. In the corresponding file directory, enter in the terminal 'python test.py'. You will get statistical results in the terminal and have discriminatory instances saved to 'logging_data/logging_data_from_tests/complete_comparison/'. Less than 30 min will be taken for a personal computer.


2 Detailed Description

2.1 Effectiveness/Efficiency Validation
We reproduce the main experiments in 'reproducing.py'. This module compares the effectiveness and efficiency between ADF and EIDIG in the settings adopted in our paper. You can run it to validate our claims. It will take a few days for a personal computer, or you can run different parts of experiments in parallel for acceleration. The statistical results will be immediately reported in the terminal, and the data for further analysis are saved to 'logging_data/logging_data_from_tests/'.

2.2 Model Evaluation
In the 'model_evaluation' folder, you can evaluate classification performance and discrimination degree on the models provided by us. Alternatively, you can retrain the models by yourself with our data, or with the data generated by 'reproducing.py', and then do the evaluation. The statistical results will also be immediately reported in the terminal.